"""Defines functions to pull and pre-process the WCS data for use with the convexity and IB-optimization model """

# Imports
import pandas as pd
import numpy as np

from typing import Tuple


def wcs_data_pull(
    wcs_data_path: str, CIELAB_path: str
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """Function to pull the world color survey data from a directory and process the data for use with the convexity
    evaluation tools from this module

    Arguments
    ---------
    wcs_data_path
        The filepath to the directory containing the WCS data. This directory must contain chip.txt, term.txt, lang.txt,
        and dict.txt. All are available for download from https://www1.icsi.berkeley.edu/wcs/data.html.
    CIELAB_path
        The filepath to the  containing the text file containing the CIELAB data. This file is available for download
        from https://www1.icsi.berkeley.edu/wcs/data.html.

    Returns
    -------
    chip_df
        Contains the chip ID, row and column numbers from the world color survey, and the chip name, for every color
        chip included in the WCS.
    term_df
        The dataframe generated by the term.txt file from the world color survey data, which contains the language id,
        speaker id, chip id and term abbreviation.
    lang_df
        The dataframe generated by the lang.txt file from the world color survey data, which contains the langauge id,
        language name, language geographical region(s), field worker identification, and four unknown fields.
    vocab_df
        The dataframe generated by the dict.txt file from the world color survey data, which contains the language id,
        term id and term abbreviation
    cielab_df
        The dataframe generated by the cnum_CIELAB_table.txt file from the world color survey data, which contains the
        color chip id, V, H, C, M hue and M value numbers (which allow for one method of representing color space), and
        the L, A, B values, which allow for our preferred method of representing color space as a subset of 3D Euclidean
        space.

    """
    chip_df = pd.read_csv(f'{wcs_data_path}/chip.txt', sep='\t', header=None)
    chip_df.columns = ['chip_id', 'wcs_row', 'wcs_col', 'chip_name']
    chip_df.sort_values(by='chip_id', inplace=True)

    term_df = pd.read_csv(f'{wcs_data_path}/term.txt', sep='\t', header=None)
    term_df.columns = ['lang_id', 'speaker_id', 'chip_id', 'term_abbrev']
    term_df.sort_values(by='chip_id', inplace=True)

    lang_df = pd.read_csv(f'{wcs_data_path}/lang.txt', sep='\t', header=None)
    lang_df.columns = ['lang_id', 'lang_name', 'lang_geo', 'UNK1', 'UNK2', 'UNK3', 'field_worker', 'UNK4']

    vocab_df = pd.read_csv(f'{wcs_data_path}/dict.txt', sep='\t', header=0)
    vocab_df.columns = ['lang_id', 'term_number', 'term', 'term_abbrev']

    cielab_df = pd.read_csv(CIELAB_path, sep='\t', header=0)
    cielab_df.columns = ['chip_id', 'V', 'H', 'C', 'm_hue', 'm_value', 'L', 'A', 'B']
    cielab_df.sort_values(by='chip_id', inplace=True)

    return chip_df, term_df, lang_df, vocab_df, cielab_df


def create_color_space_table(cielab_df: pd.DataFrame, chip_df: pd.DataFrame) -> pd.DataFrame:
    """Function that takes in the dataframe created by the raw WCS-CIELAB text file and creates the desired color-space
    dataframe that maps WCS chips to R3.

    Arguments
    ---------
    cielab_df
        The dataframe generated by the cnum-vhcm-lab-new.txt file from the world color survey data, which contains the
        WCS chip ids and their affiliated Munsell and CEILAB values.
    chip_df
        The dataframe generated by the chip.txt file from the world color survey data, which contains the WCS chip
        numbers and their affiliated row and column from the two-dimensional WCS pallet.

    Returns
    -------
    cielab_map_df
        A dataframe containing the WCS chip numbers, chip locations and CIELAB values.
    """

    # Merge dataframes
    cielab_map_df = cielab_df[['chip_id', 'L', 'A', 'B']]
    tmp_chip_df = chip_df[['chip_id', 'chip_name']]
    cielab_map_df = cielab_map_df.merge(tmp_chip_df, how='left', on='chip_id')
    cielab_map_df.sort_values(by='chip_id', inplace=True)

    return cielab_map_df

def lang_id_map(language: str, lang_df: pd.DataFrame) -> int:
    """Function to perform the  mapping between the roman-character representation of a language name and the language
    id the language has been assigned in the WCS.

    Arguments
    ---------
    language
        The name of the language for which the language id is desired.
    lang_df
        The dataframe generated by the lang.txt file from the world color survey data, which contains the langauge id,
        language name, language geographical region(s), field worker identification, and four unknown fields.

    Returns
    -------
    lang_id
        The integer id for the specified language, as defined in the WCS data.
    """

    lang_id = lang_df['lang_id'].loc[lang_df['lang_name'] == language].values[0]

    return lang_id


def create_lang_table(term_df: pd.DataFrame, vocab_df: pd.DataFrame, lang_id: int) -> pd.DataFrame:
    """Function that takes in the dictionary dataframe and term count dataframe generated from the WCS txt files and
    creates a dataframe that contains the speaker counts for each term by color chip.

    Arguments
    ---------
    term_df
        The dataframe generated by the term.txt file from the world color survey data, which contains the language id,
        speaker id, chip id and term abbreviation.
    vocab_df
        The dataframe generated by the dict.txt file from the world color survey data, which contains the language id,
        term id and term abbreviation
    lang_id
        The integer value specifying which language to generate counts for.

    Returns
    -------
    term_ct_df
        A dataframe containing the wcs chip number, number of responses generated for that chip, and counts indicating
        how many speakers associated a particular chip with each of the possible color terms.
    """

    # Get language specific rows from dataframes
    lang_term_df = term_df.loc[term_df['lang_id'] == lang_id]
    lang_vocab_df = vocab_df.loc[vocab_df['lang_id'] == lang_id]

    # Create map from term abbreviation to term number
    term_map = {}
    for i in range(lang_vocab_df.shape[0]):
        term_map[lang_vocab_df['term_abbrev'].iloc[i]] = lang_vocab_df['term_number'].iloc[i]

    # Get term counts for each color chip
    count_array = np.zeros([330, lang_vocab_df.shape[0]])
    for i in range(lang_term_df.shape[0]):
        chip_id = lang_term_df['chip_id'].iloc[i]
        term_abbrev = lang_term_df['term_abbrev'].iloc[i]
        if term_abbrev in term_map.keys():
            term_id = term_map[term_abbrev]
            count_array[chip_id - 1, term_id - 1] += 1

    # Create term count dataframe
    term_ids = list(range(1, lang_vocab_df.shape[0] + 1, 1))
    count_df = pd.DataFrame(count_array, columns=term_ids)
    chip_numbers = pd.Series(list(range(1, 331, 1)), name='chip_id')
    response_counts = pd.Series(count_array.sum(axis=1), name='response_ct')
    term_ct_df = pd.concat([chip_numbers, response_counts, count_df], axis=1)

    return term_ct_df

def create_lang_encoder_dist(term_ct_df: pd.DataFrame) -> np.array:
    """Function that converts the count dataframe output by create_lang_table into a numpy array that represents the
    color term encoder for that particular language.

    Arguments
    ---------
    term_ct_df
        A dataframe containing the wcs chip number, number of responses generated for that chip, and counts indicating
        how many speakers associated a particular chip with each of the possible color terms.

    Returns
    -------
    term_probs
        An array specifying the encoder. Specifically, a set of probability distributions over all possible color terms
        in the specified language for a given visual stimulus (i.e. given a chip from the WCS, the probability that a
        group of speakers assigns that chip a particular color term).
    """

    # Get probability values
    prob_values = term_ct_df.iloc[:, 2:]
    prob_values = prob_values.divide(term_ct_df['response_ct'], axis='rows')

    # Construct DataFrame
    term_probs = pd.concat([term_ct_df['chip_id'], prob_values], axis=1)
    term_probs.sort_values(by='chip_id', inplace=True)

    return term_probs